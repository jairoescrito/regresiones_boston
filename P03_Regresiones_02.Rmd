---
title: "COMPARACIÓN DE RESULTADOS DE MODELOS DE REGRESIÓN"
author: "Jairo Sánchez"
date: "2023-11-21"
output: html_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(ISLR2) # Librería con datasets y herramientas del libro An Introduction
# to Statistical Learning with R
library(tidyverse) # Librería para ordenamiento de arreglos de datos, incluye ggplot2
library(Metrics) # Librería para calculo de métricas de evaluación valores reales vs valores predichos
library(plotly) # Gráficas con animaciones
library(knitr) # Libería para crear tablas en archivos Knit html# gráficos interactivos
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Carga de datos actualizados en la parte anterior
Train <- as.data.frame(read_csv("Train.csv", col_types = cols(chas = col_factor()
                                                , rad = col_factor())))
Test <- as.data.frame(read_csv("Test.csv", col_types = cols(chas = col_factor(), 
                                              rad = col_factor())))
RMSE_2 <- read_csv("RMSE_1.csv")
```

```{=html}
<center>
<h1>Parte 3: Regresiones lineales múltiples</h1>
</center>
```
## Introducción

En la [parte 2](https://rpubs.com/jairoescrito/Regresiones_2) de este documento se presentaron los resultados de modelos de regresión lineal simple (en función de una sola variable independiente) haciendo uso de los conjuntos de datos Train (para establecimiento de las regresiones) y Test (para la evaluación de los modelos. Para los modelos a continuación se trabaja con los mismos conjuntos de datos a fin de que sea coherente la comparación de los resultados del RMSE.

Los modelos desarrollados se enfocan en el uso de al menos dos variables independientes en el mismo modelo. Las variables seleccionadas para estos se hacen de acuerdo a los resultados de los coeficientes de correlación expuestos en la [parte 1](https://rpubs.com/jairoescrito/Regresiones_1) del documento.

### 3.1. Regresión lineal múltiple con todas las variables independientes

```{r echo=FALSE, message=FALSE, warning=FALSE}
lm_full<-lm(medv~.,data=Train)
resumen_full <- summary(lm_full)
resumen_full
```

El modelo expuesto explica alrededor de un 73% la variabilidad de *medv*, con un error estándar residual de 4.88 miles de dólares frente a los valores reales. No todos los estimadores de la pendiente de cada una de las 12 variables independientes podrían considerarse diferentes a cero, al verificar los p-valores, se concluye que es posible excluir las variables *age* e *indus, esto* sin que se presenten cambios relevantes en el nivel de variabilidad explicado y el error estándar residual, escenario que se verificará en el próximo modelo a evaluar.

Uno aspecto importante a resaltar es el modelo incluye dos variables categóricas:

-   chas: toma dos niveles, 1 y 0. En el modelo se incluye la variables chas0

-   rad: toma nueve niveles, 24, 8, 7, 6, 5, 4, 3, 2, 1. El modelo incluye las variables rad1 a rad8. De estas, rad3, rad7 y rad8, presentan p-valores altos por lo que las mismas se pueden excluir del modelo definitivo

```{r echo=FALSE, message=FALSE, warning=FALSE}
coeficientes_full <- as.data.frame(resumen_full$coefficients)
coeficientes_full <- rownames_to_column(coeficientes_full)
modelo_full <- data.frame(coeficientes_full[,1][coeficientes_full$`Pr(>|t|)`<0.05],
                          coeficientes_full[,2][coeficientes_full$`Pr(>|t|)`<0.05])
names(modelo_full) <- c("Variable", "Coeficiente Estimado")
knitr :: kable(modelo_full)
```

La predicción de los resultados de medv para el conjunto de datos Test comparados con los valores reales se verían de la siguiente manera

```{r echo=FALSE, message=FALSE, warning=FALSE}
p_full <- predict(lm_full,Test)
data_reg <- cbind(Test,round(p_full,1))
nombres <- names(Test) 
nombres <- c(nombres,"medv_predict_full")
names(data_reg) <-nombres 
rm(nombres)
data_reg<- arrange(data_reg,medv)
data_reg$Obs <- rep(1:nrow(Test))
data_reg<- data_reg %>% relocate(Obs,.before = crim)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
fig_rlmfull <- plot_ly(data = data_reg, x = ~Obs) # Definición básica de la gráfica
fig_rlmfull <- fig_rlmfull %>% add_trace(y = ~medv, # Agregar trazado de datos reales
                                           mode = 'lines+markers',
                                           name = 'medv_real')
fig_rlmfull <- fig_rlmfull %>% add_trace(y = ~medv_predict_full, # Agregar trazado de datos predicción
                                           mode = 'lines+markers',
                                           name = 'medv_predicción_12vars')
fig_rlmfull <- fig_rlmfull %>% layout(title = list(text ='Regresión lineal múltiple 12vars',
                                                     y = 0.97, x = 0.1),
                                        xaxis = list(title = 'Observación'),
                                        yaxis = list(title = 'medv'), 
                                        legend = list(orientation = 'h', 
                                                      x = 0.3, y = -0.2))
#Mostrar gráfico
fig_rlmfull
```

La diferencia más relevante en el la regresión lineal múltiple, que incluye las 12 variables independientes, se observa para valores *medv* que son superiores a 29, rango en el que el modelo tiende a predecir valores menores que lo datos reales. Para los demás rangos de datos los resultados de la predicción tienden a mantenerse cerca de los valores reales, aunque se presentan algunas rachas, en especial, por encima de los valores reales (para valores *medv* reales entre 23.3 y 24.5).

Cabe resaltar que el modelo lineal no es posible presentarlo gráficamente debido a la cantidad de variables.

### 3.2. Regresión lineal múltiple con dos variables independientes

```{r echo=FALSE, message=FALSE, warning=FALSE}
lm_2v<-lm(medv~rm+lstat,data=Train)
summary(lm_2v)
```

En el planteamiento del modelo de regresión con dos variables, se observa un dato un poco mayor del 62% de representación de la variabilidad de *medv* y un error estándar residual de 5.75 miles de dólares. De acuerdo a los resultados en la estimación de los coeficientes, la ecuación del modelo sería así:

$$
medv = 4.70460*rm - 0.65792*lstat + 1.36638
$$

Una vez realizada la predicción de datos con el modelo anterior, los resultados reales frente a los de predicción presentados como dispersión en un espacio XYZ se observan así:

```{r echo=FALSE, message=FALSE, warning=FALSE}
p_2v <- predict(lm_2v,Test)
data_reg <- rownames_to_column(data_reg,"Ind")
data_reg$Ind <- as.numeric(data_reg$Ind)
nombres <- names(data_reg)
nombres <- c(nombres,"medv_predict_2v")
data_reg<- arrange(data_reg,Ind)
data_reg <- cbind(data_reg,round(p_2v,1))
names(data_reg) <-nombres
rm(nombres)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
fig_rlm2v <- plot_ly(data = data_reg, x = ~lstat, y = ~rm) # Definición básica de la gráfica
fig_rlm2v <- fig_rlm2v %>% add_trace(z = ~medv, # Agregar trazado de datos reales
                                           mode = 'markers',
                                           size = 0,
                                           name = 'medv_real')
fig_rlm2v <- fig_rlm2v %>% add_trace(z = ~medv_predict_2v, # Agregar trazado de datos predicción
                                           mode = 'markers',
                                           size = 0,
                                           name = 'medv_predicción_2vars')
fig_rlm2v <- fig_rlm2v %>% layout(title = list(text ='Regresión lineal múltiple con 2 variables',
                                                     y = 0.97, x = 0.1),
                                        legend = list(orientation = 'h', 
                                                      x = 0.28, y = -0.2))
fig_rlm2v # Mostrar gráfico
```

Como se ha observado hasta el momento, para cada una de las regresiones lineales, los modelos presentan dificultades en la predicción de valores de *medv* que tienen valores reales altos, en la gráfica se pueden detectar que los valores *medv* reales superiores a 41 tienen predicciones inferiores, esto es, valores alrededor de 10 por debajo del real.

### 3.4 Comparación de regresiones lineales múltiples

La comparación de los dos modelos planteados en esta parte del documento se observa en la siguiente gráfica

```{r echo=FALSE, message=FALSE, warning=FALSE}
data_reg<- arrange(data_reg,medv)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
fig_rlm <- plot_ly(data = data_reg, x = ~Obs) # Definición básica de la gráfica
fig_rlm <- fig_rlm %>% add_trace(y = ~medv, # Agregar trazado de datos reales
                                           mode = 'lines+markers',
                                           name = 'medv_real')
fig_rlm <- fig_rlm %>% add_trace(y = ~medv_predict_full, # Agregar trazado de datos predicción
                                           mode = 'lines+markers',
                                           name = 'medv_predicción_todas')
fig_rlm <- fig_rlm %>% add_trace(y = ~medv_predict_2v, # Agregar trazado de datos predicción
                                           mode = 'lines+markers',
                                           name = 'medv_predicción_2vars')
fig_rlm <- fig_rlm %>% layout(title = list(text ='Regresión lineal múltiple',
                                                     y = 0.97, x = 0.1),
                                        xaxis = list(title = 'Observación'),
                                        yaxis = list(title = 'medv'), 
                                        legend = list(orientation = 'h', 
                                                      x = 0.15, y = -0.2))
#Mostrar gráfico
fig_rlm
```

Los dos modelos no reflejan diferencias significativas en su predicción, sin embargo, en cuanto al modelo de dos variables parece tener un mejor desempeño en las predicciones para valores reales de *medv* menores a 37 mientras que las predicciones superiores a este valor tienen resultados ligeramente más alejados de los valores reales en comparación con el modelo que incluye todas las variables. Cabe resaltar que estas conclusiones se soportan en la percepción visual que brinda la gráfica. La cuantificación de la "calidad" en las predicciones se presentará con el cálculo del RMSE.

#### **3.4.1 Cálculo del RMSE**

Se calculan tres valores de RMSE, uno para cada expuesto, que a su vez se compararán con los ya calculados para los modelos de regresión lineal simple de la parte 2 de este documento.

El RMSE del modelo todas las variables se calcula en 4.32 y el de 2 variables en 4.63. Estos resultados permiten concluir que los modelos con más variables presentan predicciones más cercanas a los valores reales. La diferencia en el RMSE entre los dos modelos es alrededor de 310 dólares, valor que podría no ser significativo. Se resalta que si se observa una diferencia importante con los modelos de regresión lineal simple pues la diferencia entre RMSE está en torno a los mil dólares.

```{r echo=FALSE, message=FALSE, warning=FALSE}
e_full <- round(rmse(data_reg$medv,data_reg$medv_predict_full),2)
e_2vars <- round(rmse(data_reg$medv,data_reg$medv_predict_2v),2)
RMSE_2 <- as.data.frame(rbind(RMSE_2,e_full,e_2vars))
RMSE_2[,1] <- c("01_RLS_lstat","02_RLS_rm","03_RLM_12vars","04_RLM_2vars")
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
fig_rmse <- plot_ly(RMSE_2, x = ~Modelo, y = ~RMSE, 
                type = "scatter", 
                mode = "markers+lines")
fig_rmse
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
write_csv(RMSE_2,"RMSE_2.csv")
```
