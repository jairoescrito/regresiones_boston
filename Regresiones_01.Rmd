---
title: "COMPARACIÓN DE RESULTADOS DE MODELOS DE REGRESIÓN"
author: "Jairo Sánchez"
date: "2023-11-20"
output: html_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(ISLR2) # Librería con datasets y herramientas del libro An Introduction
# to Statistical Learning with R
library(tidyverse) # Librería para ordenamiento de arreglos de datos, incluye ggplot2
library(Metrics) # Librería para calculo de métricas de evaluación valores reales vs valores predichos
library(plotly) # gráficos interactivos
```

```{=html}
<center>
<h1>Parte 2: Regresiones lineales simples</h1>
</center>
```
## Introducción

Partiendo de los resultados de la [primera parte](https://rpubs.com/jairoescrito/Regresiones_1) del documento, los modelos de regresión lineal simple que se plantean se enfocan en mostrar los modelos de la variable *medv* en función de las dos variables independientes con mayor coeficiente de correlación, esto es, las variable *lstat* (R = -0.74) y *rm* (R = 0.70).

Pare el desarrollo de este ejercicio se divide el conjunto de datos (Boston) y se divide en dos partes "train" y "test", con el primer conjunto se define el modelo de regresión lineal y con el segundo se evalúa calculando el resultado del RMSE (Root Mean Squared Error), esto es, la raíz del error cuadrado medio. La división de los datos se plantea en 80% para train y 20% para test, es decir, de las 506 observaciones que incluye Boston, 401 se usan para definición del modelo y 101 para la evaluación. (se define set.seed(2023)).

```{r echo=FALSE, message=FALSE, warning=FALSE}
Data <- Boston
Data$rad <- as.factor(Data$rad) # convertir a categórica
Data$chas <- as.factor(Data$chas) # convertir a categórica
# División del conjunto de datos
set.seed(2023) # semilla para obtener siempre la misma aleatoriedad
P<-0.8 # Proporción definida en el 80%
Ind<-sample(1:nrow(Data),
            size=(round(nrow(Data)*P,0))
            ,replace=FALSE)
Train<-Data[Ind,]
Test<-Data[-Ind,]
rm(P,Ind)
write_csv(Train,"Train.csv")
write_csv(Test,"Test.csv")
```

Una vez realizada la division de los datos en los subconjuntos "Train" y "Test" -sobre la variable medv- se observa de la siguiente manera

```{r echo=FALSE, message=FALSE, warning=FALSE}
BindsTn <- round(1+log2(length(Train$medv)))
fig <- plot_ly(alpha = 0.7, nbinsx = BindsTn)
fig <- fig%>% add_histogram(Train$medv, name = "Train",
                            marker = list(color = "lightgreen",
                            line = list(color = "darkgreen",
                                        width = 1)))
fig <- fig%>% add_histogram(Test$medv, name = "Test",
                            marker = list(color = "lightblue",
                            line = list(color = "blue",
                                        width = 1)))
fig <- fig %>% layout(barmode = "overlay", 
                      yaxis = list(title = "# Observaciones"),
                      xaxis = list(title = "Valores para Medv"))
fig
```

### 2.1. Regresión lineal simple para ***lstat***

```{r echo=FALSE, message=FALSE, warning=FALSE}
lm_lstat<-lm(medv~lstat,data=Train)
summary(lm_lstat)
```

Los resultados muestran que esta regresión explica en un 54% la variación de los datos de la variable de respuesta, en promedio los resultados de *medv* de la predicción difieren en 6.32 miles de dólares con respecto a los valores reales.

El estimador de la pendiente es estadísticamente válido, es decir, se concluye que el mismo es diferente de cero.

El modelo lineal se escribiría de la siguiente manera

$$
medv = -0.95098*lstat +34.64358 
$$

```{r echo=FALSE, message=FALSE, warning=FALSE}
p_lstat <- predict(lm_lstat,Test)
data_reg <- data.frame(Test$lstat,Test$medv,round(p_lstat,1))
names(data_reg) <- c("lstat_test","medv_test","medv_predict_lstat")
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
fig_lm_lstat <- plot_ly(data = data_reg, x = ~lstat_test) # Definición básica de la gráfica
fig_lm_lstat <- fig_lm_lstat %>% add_trace(y = ~medv_test, # Agregar trazado de datos reales
                                           mode = 'markers',
                                           name = 'medv_test')
fig_lm_lstat <- fig_lm_lstat %>% add_trace(y = ~medv_predict_lstat, # Agregar trazado de datos de predicción
                                           mode = 'lines+markers',
                                           name = 'medv_predict_lstat')
# Agregar detalles del gráfico
fig_lm_lstat <- fig_lm_lstat %>% layout(title = list(text ='Regresión lineal simple - lstat',
                                                     y = 0.97, x = 0.1),
                                        xaxis = list(title = 'lstat'),
                                        yaxis = list(title = 'medv'), 
                                        legend = list(title=list(text='Datos')))
# dibujar gráfica
fig_lm_lstat
```

### 2.2. Regresión lineal simple para ***rm***

```{r echo=FALSE, message=FALSE, warning=FALSE}
lm_rm<-lm(medv~rm,data=Train)
summary(lm_rm)
```

En esta segunda regresión se observa un valor 46% en cuanto al nivel de variación que explica el modelo en función de la variable *rm*, adicionalmente resultados de *medv* se alejan en 6.86 miles de dólares de los valores reales.

En este caso, el estimador de la pendiente también se observa estadísticamente válido, este es diferente de cero.

El modelo lineal se escribiría de la siguiente manera

$$
medv = 8.9041*rm -33.4528 
$$

```{r echo=FALSE, message=FALSE, warning=FALSE}
p_rm <- predict(lm_rm,Test)
data_reg <- cbind(data_reg,Test$rm,round(p_rm,1))
names(data_reg) <- c("lstat_test","medv_test","medv_predict_lstat","rm_test","medv_predict_rm")
data_reg<- data_reg %>% relocate(rm_test,.after = lstat_test)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
fig_lm_rm <- plot_ly(data = data_reg, x = ~rm_test) # Definición básica de la gráfica
fig_lm_rm <- fig_lm_rm %>% add_trace(y = ~medv_test, # Agregar trazado de datos reales
                                           mode = 'markers',
                                           name = 'medv_test')
fig_lm_rm <- fig_lm_rm %>% add_trace(y = ~medv_predict_rm, # Agregar trazado de datos de predicción
                                           mode = 'lines+markers',
                                           name = 'medv_predict_rm')
# Agregar detalles del gráfico
fig_lm_rm <- fig_lm_rm %>% layout(title = list(text ='Regresión lineal simple - rm',
                                                     y = 0.97, x = 0.1),
                                        xaxis = list(title = 'rm'),
                                        yaxis = list(title = 'medv'), 
                                        legend = list(title=list(text='Datos')))
# dibujar gráfica
fig_lm_rm
```

### 2.3. Comparación de regresiones lineales simples

Con los resultados expuestos en el punto 2.1 y 2.2 se tiene un dato inicial de la "precisión" de los modelos en referencia a la garantía de los datos que pueden predecir, esto es, que tan alejado podría estar el dato predicho frente al dato real. Para cada modelo se presentó gráficamente los datos reales y la línea de regresión. En este punto se pretende cuantificar la diferencia observada en las gráficas mediante el cálculo del RMSE.

La siguiente gráfica presenta los datos reales de la variable *medv* (organizados de menor a mayor) y los valores de la predicción de cada uno de los dos modelos

```{r echo=FALSE, message=FALSE, warning=FALSE}
data_reg<- arrange(data_reg,medv_test)
data_reg$Obs <- rep(1:nrow(Test)) 
data_reg<- data_reg %>% relocate(Obs,.before = lstat_test)
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
fig_rls <- plot_ly(data = data_reg, x = ~Obs) # Definición básica de la gráfica
fig_rls <- fig_rls %>% add_trace(y = ~medv_test, # Agregar trazado de datos reales
                                           mode = 'lines+markers',
                                           name = 'medv_test')
fig_rls <- fig_rls %>% add_trace(y = ~medv_predict_lstat, # Agregar trazado de datos de predicción
                                           mode = 'lines+markers',
                                           name = 'medv_predict_lstat')
# Agregar detalles del gráfico
fig_rls <- fig_rls %>% add_trace(y = ~medv_predict_rm, # Agregar trazado de datos de predicción
                                           mode = 'lines+markers',
                                           name = 'medv_predict_rm')
# Agregar detalles del gráfico
fig_rls <- fig_rls %>% layout(title = list(text ='Modelos de regresión lineal',
                                                     y = 0.97, x = 0.1),
                                        xaxis = list(title = 'Observación'),
                                        yaxis = list(title = 'medv'), 
                                        legend = list(orientation = 'h', 
                                                      x = 0.15, y = -0.2))
# dibujar gráfica
fig_rls
```

Para los valores menores de *medv* la predicción del modelo en función de *rm* tiende a predecir valores más altos de los esperados mientras que el modelo en función de *lstat* tienden a ubicarse mucho más cerca del valor real. Para los valores medios de *medv* ambos modelos tienden a predecir valores más cercanos de los valores reales, no obstante el modelo en función de *lstat* presentan resultados que tienden a ubicarse por encima del valor real. Finalmente, para los valores altos de *mdev* los valores del modelo en función de *rm* tienden a predecir resultados más cercanos a los reales mientras que el modelo en función de *lstat* tienden a ser más distantes.

#### 2.3.1. Cálculo del RMSE

El cálculo del RMSE se realiza conforme a la siguiente ecuación:

![](images/Captura%20de%20pantalla%20de%202023-11-20%2019-44-19.png){width="191"}

Donde a es el valor real mientras que â es el valor de la predicción.

Para el modelo de regresión lineal simple en función de la variable *lstat* el resultado fue de 5.76, es decir, las predicciones con este modelo difiere en 5.76 miles de dólares, en promedio frente al dato real; en el caso del modelo en función de la variable *rm* el resultado se observa en 5.56, esto es, la predicciones que se obtienen con dicho modelo pueden ser mayores o menores en 5.56 miles de dólares con respecto al valor real.

```{r echo=FALSE, message=FALSE, warning=FALSE}
e_lstat <- round(rmse(data_reg$medv_test,data_reg$medv_predict_lstat),2)
e_rm<- round(rmse(data_reg$medv_test,data_reg$medv_predict_rm),2)
RMSE_1 <- as.data.frame(rbind(e_lstat,e_rm))
RMSE_1 <- rownames_to_column(RMSE_1)
RMSE_1[,1] <- c("RLS_lstat","RLS_rm")
names(RMSE_1) <- c("Modelo","RMSE")
fig_rmse <- plot_ly(RMSE_1, x = ~Modelo, y = ~RMSE, 
                type = "scatter", 
                mode = "markers+lines")
fig_rmse
```

Con estos resultados se concluye que para los modelos de regresión lineal estudiados, el modelo de predicción de la variable de respuesta medv en función de la variable rm tiene un nivel de error menor, no obstante, la diferencia de los errores entre los dos modelos es de apenas de 200 dólares en el promedio del error por lo que esta diferencia podría no ser significante.

```{r echo=FALSE, message=FALSE, warning=FALSE}
write_csv(RMSE_1,"RMSE_1.csv")
```
