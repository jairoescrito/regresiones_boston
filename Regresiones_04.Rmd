---
title: "COMPARACIÓN DE RESULTADOS DE MODELOS DE REGRESIÓN"
author: "Jairo Sánchez"
date: "2023-11-24"
output: html_document
---

```{r echo=FALSE, message=FALSE, warning=FALSE}
library(tidyverse) # Librería para ordenamiento de arreglos de datos, incluye ggplot2
library(Metrics) # Librería para calculo de métricas de evaluación valores reales vs valores predichos
library(plotly) # gráficos interactivos
library(glmnet) # Incluye las funciones necesarias para generar metodos de regularización
```

```{r echo=FALSE, message=FALSE, warning=FALSE}
# Carga de datos actualizados en la parte anterior
Train <- read_csv("Train.csv")
Test <- read_csv("Test.csv")
RMSE_4 <- read_csv("RMSE_3.csv")
```

```{=html}
<center>
<h1>Parte 5: Regularización</h1>
</center>
```
## Introducción

En los modelos de regresión que se han planteado se han contemplado únicamente modelos lineales; en este orden de ideas, se presenta los dos últimos modelos de este orden, los cuales corresponden a métodos de regularización, estos parten del modelo de regresión lineal al que se adiciona un factor de contracción. Las regresiones Ridge (L2) y Lasso (L1) son los métodos de regularización que se soportan en la minimización del RSS (Suma de residuos al cuadrado) al cual se le agrega un factor de penalización (o factor de contracción). El soporte matemático del método de regularización no es objeto del presente documento, sin embargo, una fuente recomendada para consultar o conocer el soporte teórico se encuentra en el la sección 6.2 del libro [An Introduction to Statistical Learning](https://www.statlearning.com/) Segunda edición, de los autores *James, G., Witten, D., Hastie, T., & Tibshirani.*

El desarrollo de esta parte del documento se soporta también en la sección 6.5.2 del libro ya mencionado; en este se recomienda el uso del método "validación cruzada tipo k-fold" con el fin de encontrar el factor de penalización que presente el mínimo de error en el modelo.

## 5. Regularización

### 5.1. Validación cruzada tipo k-fold

R.Chollet, F., & Allaire, J. J en su libro [Deep Learning with R](https://www.manning.com/books/deep-learning-with-r) mencionan que cuando un conjunto de datos no tiene una cantidad considerable de observaciones es recomendable hacer uso de la validación cruzada. No es muy claro (por lo menos en mi caso, no he encontrado una "formula" que me permita conocer el dato) cuál es la cantidad de observaciones óptima para concluir que son suficientes para trabajar únicamente con los subconjuntos Train y Test. La literatura si menciona que se debe procurar un "equilibrio" entre la cantidad de dimensiones (variables) y la cantidad de observaciones. Si se plantea que tenemos alrededor de 39 observaciones por cada variable (incluida la dependiente) se podría concluir que son muy pocas ya que en el libro en mención, en la sección 4.3.4, se dice que este conjunto de datos (Boston) posee muy pocas observaciones, y que plantear un subconjunto de validación (Test) con 100 observaciones (en promedio) es insuficiente, pues podría suceder que este subconjunto no represente adecuadamente el nivel de varianza que incluye el conjunto de entrenamiento (Train) y viceversa. En aquellos modelos de regresión en lo que se requiere encontrar el el optimo de uno o varios parámetros de tal manera que se minimice el error total del modelo,y que a su vez se tengan pocas observaciones, debería hacerse uso de la validación cruzada.

Existen varios métodos de validación cruzada, no obstante, para este planteamiento se usará la validación cruzada tipo k-fold, este consiste en dividir el conjunto de entrenamiento en k "pliegues" a fin de entrenar el modelo k veces, cada k entrenamiento entregará un valor de error (según la métrica de evaluación seleccionada), al final se hará un promedio de los k errores y este será el error de entrenamiento. En cada k entrenamiento se usa uno de los k pliegues para validar el entrenamiento que se hace con los k-1 pliegues restantes. Para un valor K = 5 lo anterior se observaría así:

![](images/Captura%20de%20pantalla%20de%202023-11-23%2016-25-31.png)

```{r echo=FALSE, message=FALSE, warning=FALSE}
Xt <- model.matrix(medv~., Train)[,-1] # Matriz para modelo lineal, convierte variables categóricas en dummy, se elimina la columna de intercepto que se crea
Yt <- as.matrix(Train[,13])
```

### 5.2. Regresión Ridge

El método de regularización ridge (L2) incluye, como factor de penalización en el RSS, la sumatoria de los coeficientes (de cada variable) al cuadrado y multiplicado por un valor lambda.

![](images/Captura%20de%20pantalla%20de%202023-11-27%2013-51-07.png)

El modelo ridge que se presenta incluye el parámetro k = 5 en la validación cruzada k-fold (set.seed(2023)).

```{r}
set.seed(2023)
lm_ridge <- cv.glmnet(x = Xt, y = Yt, alpha = 0.5, nfolds = 5) # Alpha = 0 para regularización tipo ridge
lm_ridge$lambda
plot(lm_ridge)
coef(lm_ridge)
```

```{r}
min(lm_ridge$lambda)
```
